{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Print TensorFlow version (must be 2.18)\n",
        "print(\"TensorFlow Version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 1 - DATA PREPROCESSING\n",
        "\n",
        "Step 1: Organize your dataset in the following folder structure:\n",
        "\n",
        "dataset\\\n",
        "├── train\\\n",
        "│   ├── good\\\n",
        "│   └── defective\\\n",
        "└── test\\\n",
        "    ├── good\\\n",
        "    └── defective\\\n",
        "\n",
        "\n",
        "Each image should be placed in the corresponding class folder.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1498 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess training data\n",
        "train_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    'C:/Users/lenovo/Downloads/CNN_project/dataset/train',\n",
        "    image_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    label_mode='binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation to improve model generalization\n",
        "train_data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255),    # Normalize pixel values\n",
        "    tf.keras.layers.RandomFlip('horizontal'), # Random horizontal flip\n",
        "    tf.keras.layers.RandomZoom(0.2),    # Zoom-in effects\n",
        "    tf.keras.layers.RandomRotation(0.2),    # Random rotation\n",
        "    tf.keras.layers.RandomShear(0.2)    # Shear transformation\n",
        "])\n",
        "\n",
        "# Apply augmentation to the training dataset\n",
        "augmented_train_dataset = train_set.map(lambda x, y: (train_data_augmentation(x, training=True), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 358 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess test data (no augmentation, just normalization)\n",
        "test_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    'C:/Users/lenovo/Downloads/CNN_project/dataset/test',\n",
        "    image_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    label_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "augmented_test_dataset = test_set.map(lambda x, y: (test_data_augmentation(x, training=False), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " BUILDING THE CNN MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "cnn = tf.keras.models.Sequential([\n",
        "    # First convolutional layer\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
        "\n",
        "    # Second convolutional layer\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
        "\n",
        "    # Flattening the output of conv layers\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected layer\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "\n",
        "    # Output layer for binary classification\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "The model will train for 25 epochs and show accuracy and loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 998ms/step - accuracy: 0.5208 - loss: 0.7475 - val_accuracy: 0.2765 - val_loss: 0.8172\n",
            "Epoch 2/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.6680 - loss: 0.6357 - val_accuracy: 0.4106 - val_loss: 1.4595\n",
            "Epoch 3/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.6904 - loss: 0.6060 - val_accuracy: 0.4637 - val_loss: 1.3416\n",
            "Epoch 4/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.6790 - loss: 0.6041 - val_accuracy: 0.6425 - val_loss: 0.8160\n",
            "Epoch 5/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.6761 - loss: 0.6043 - val_accuracy: 0.5363 - val_loss: 1.1305\n",
            "Epoch 6/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.6916 - loss: 0.5987 - val_accuracy: 0.6313 - val_loss: 0.8726\n",
            "Epoch 7/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 938ms/step - accuracy: 0.6876 - loss: 0.6149 - val_accuracy: 0.6089 - val_loss: 0.8840\n",
            "Epoch 8/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 917ms/step - accuracy: 0.6871 - loss: 0.6002 - val_accuracy: 0.5894 - val_loss: 0.9231\n",
            "Epoch 9/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 901ms/step - accuracy: 0.6753 - loss: 0.6063 - val_accuracy: 0.5782 - val_loss: 1.1095\n",
            "Epoch 10/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 894ms/step - accuracy: 0.6772 - loss: 0.5981 - val_accuracy: 0.5084 - val_loss: 1.1727\n",
            "Epoch 11/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.7118 - loss: 0.5746 - val_accuracy: 0.6061 - val_loss: 0.9082\n",
            "Epoch 12/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.7127 - loss: 0.5856 - val_accuracy: 0.5503 - val_loss: 1.0245\n",
            "Epoch 13/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 980ms/step - accuracy: 0.6937 - loss: 0.5886 - val_accuracy: 0.5028 - val_loss: 1.1031\n",
            "Epoch 14/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 942ms/step - accuracy: 0.7103 - loss: 0.5804 - val_accuracy: 0.5531 - val_loss: 1.0442\n",
            "Epoch 15/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 969ms/step - accuracy: 0.7039 - loss: 0.5704 - val_accuracy: 0.7039 - val_loss: 0.6657\n",
            "Epoch 16/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 985ms/step - accuracy: 0.6929 - loss: 0.5894 - val_accuracy: 0.4469 - val_loss: 1.1552\n",
            "Epoch 17/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.7214 - loss: 0.5554 - val_accuracy: 0.4469 - val_loss: 1.1357\n",
            "Epoch 18/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.7153 - loss: 0.5552 - val_accuracy: 0.6844 - val_loss: 0.7554\n",
            "Epoch 19/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.6831 - loss: 0.5831 - val_accuracy: 0.5587 - val_loss: 0.9525\n",
            "Epoch 20/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.7094 - loss: 0.5614 - val_accuracy: 0.6145 - val_loss: 0.9588\n",
            "Epoch 21/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.6936 - loss: 0.5712 - val_accuracy: 0.6620 - val_loss: 0.7372\n",
            "Epoch 22/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.7079 - loss: 0.5652 - val_accuracy: 0.5754 - val_loss: 0.9951\n",
            "Epoch 23/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.7065 - loss: 0.5563 - val_accuracy: 0.4693 - val_loss: 1.0650\n",
            "Epoch 24/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.7000 - loss: 0.5627 - val_accuracy: 0.4609 - val_loss: 1.1803\n",
            "Epoch 25/25\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.7246 - loss: 0.5502 - val_accuracy: 0.6117 - val_loss: 0.8840\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x16347708170>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(\n",
        "    x=augmented_train_dataset,\n",
        "    validation_data=augmented_test_dataset,\n",
        "    epochs=25\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model saved to: your_trained_model.keras\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model to disk\n",
        "model_save_path = 'your_trained_model.keras'\n",
        "cnn.save(model_save_path)\n",
        "print(f\"✅ Model saved to: {model_save_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
